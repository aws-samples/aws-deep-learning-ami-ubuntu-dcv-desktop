services:
  server_0:
    image: ${IMAGE}
    command: ${COMMAND}
    environment:
      - MODEL_ID=${MODEL_ID}
      - HF_HOME=/snapshots/huggingface
      - HF_TOKEN=${HF_TOKEN}
      - OMP_NUM_THREADS=${OMP_NUM_THREADS:-16}
      - MAX_MODEL_LEN=${MAX_MODEL_LEN:-8192}
      - TENSOR_PARALLEL_SIZE=${TENSOR_PARALLEL_SIZE:-1}
      - MAX_NUM_SEQS=${MAX_NUM_SEQS:-8}
      - TRTLLM_CONVERT_CKPT_SCRIPT=${TRTLLM_CONVERT_CKPT_SCRIPT}
      - TRITON_LAUNCH_SCRIPT=${TRITON_LAUNCH_SCRIPT}
      - DEVICE=cuda
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: ${NUM_DEVICE}
              capabilities: [gpu]
    shm_size: 32Gb
    volumes:
      - ${HOME}/scripts:/scripts:ro
      - ${HOME}/snapshots:/snapshots:rw
    ports:
      - "8080:8080"